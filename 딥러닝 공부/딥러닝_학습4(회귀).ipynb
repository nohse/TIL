{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**파이토치로 선형 회귀 구현**"
      ],
      "metadata": {
        "id": "TbXumgWzLvMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAkBSHLuCxD6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 실습하고 있는 파이썬 코드를 재실행해도 다음에도 같은 결과가 나오도록 랜덤 시드(random seed)를 줍니다.\n",
        "torch.manual_seed(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4za6UVVDFeh",
        "outputId": "524668fe-6087-42a9-b71c-dccee0fb3be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c62f9fadbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1999 # 원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opJ4Q5gPK4lD",
        "outputId": "bdc03552-eaa3-42c2-8382-ffae1a5e9a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1999 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/1999 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/1999 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/1999 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/1999 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/1999 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/1999 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다중선형회귀**"
      ],
      "metadata": {
        "id": "xF3mnphwMvx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "ZKbELi8DK44Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1b4dumVMydD",
        "outputId": "2dcb86ed-0fbc-493f-fa5a-d7ee02a75682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c62f9fadbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**파이토치로 기초 구현**"
      ],
      "metadata": {
        "id": "wJ6FEiR0OXjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 가중치 w와 편향 b 초기화\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b85OP1ZNM0St",
        "outputId": "33468282-8740-4fcf-fe4f-b2b617475565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "벡터와 행렬 연산으로 **바꾸기**"
      ],
      "metadata": {
        "id": "ESNDDH0qOcCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  80],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "    ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeXg4uMnORrD",
        "outputId": "1682f665-806a-4403-dc19-ac3cd01f0378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch    1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
            "Epoch    2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]) Cost: 3069.590088\n",
            "Epoch    3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670288\n",
            "Epoch    4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481873\n",
            "Epoch    5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n",
            "Epoch    6/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687496\n",
            "Epoch    7/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n",
            "Epoch    8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365656\n",
            "Epoch    9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
            "Epoch   10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n",
            "Epoch   11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n",
            "Epoch   12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n",
            "Epoch   13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n",
            "Epoch   14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n",
            "Epoch   15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
            "Epoch   16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
            "Epoch   17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
            "Epoch   18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
            "Epoch   19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n",
            "Epoch   20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module로 구현하는 선형 회귀"
      ],
      "metadata": {
        "id": "AjmgbXmxQ2St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q111-B4OSP9",
        "outputId": "7d36e6b3-3d66-4554-f950-774bf355989c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c62f9fadbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
        "model = nn.Linear(1,1)\n",
        "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward() # backward 연산\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8cwfxJLQ-i9",
        "outputId": "dcead988-a821-4bfd-a74a-167e0805fb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEy4BaqsRXfd",
        "outputId": "d0c5ca61-ca6d-4d83-eaee-6573e7a3e70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.Module로 구현하는 다중 선형 회귀**"
      ],
      "metadata": {
        "id": "tiqyAEdTSJw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward()\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgqWCG5yRpmV",
        "outputId": "18c7db5a-52f9-4743-aee8-02a2658bc76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225993\n",
            "Epoch  200/2000 Cost: 0.223911\n",
            "Epoch  300/2000 Cost: 0.221941\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218271\n",
            "Epoch  600/2000 Cost: 0.216575\n",
            "Epoch  700/2000 Cost: 0.214950\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211952\n",
            "Epoch 1000/2000 Cost: 0.210560\n",
            "Epoch 1100/2000 Cost: 0.209232\n",
            "Epoch 1200/2000 Cost: 0.207967\n",
            "Epoch 1300/2000 Cost: 0.206761\n",
            "Epoch 1400/2000 Cost: 0.205619\n",
            "Epoch 1500/2000 Cost: 0.204522\n",
            "Epoch 1600/2000 Cost: 0.203484\n",
            "Epoch 1700/2000 Cost: 0.202485\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200635\n",
            "Epoch 2000/2000 Cost: 0.199769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델을 클래스로 구현하기**"
      ],
      "metadata": {
        "id": "oeJlgEs3TFvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단순 선형 회귀 클래스 구현**"
      ],
      "metadata": {
        "id": "KStgWYdvTvu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NEv75LZSXKZ",
        "outputId": "49a02582-3809-4e25-b833-81dc58de901b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c62f9fadbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "RLSJiRKsTucD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n"
      ],
      "metadata": {
        "id": "iyNw7v4cT1CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionModel()\n",
        "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward() # backward 연산\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWtfmxYBT13O",
        "outputId": "051ad481-836d-471e-af90-fdc7eae59528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**미니 배치와 데이터 로드**"
      ],
      "metadata": {
        "id": "ezezKzTOUjXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더\n"
      ],
      "metadata": {
        "id": "-ktaRXKrUmao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  90],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "model = nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9uRAV8dT-qd",
        "outputId": "ecc19e33-7b2d-4cb7-ead2-0ceb8a6cb28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Batch 1/3 Cost: 35302.484375\n",
            "Epoch    0/100 Batch 2/3 Cost: 8671.646484\n",
            "Epoch    0/100 Batch 3/3 Cost: 3903.019531\n",
            "Epoch    1/100 Batch 1/3 Cost: 1116.219604\n",
            "Epoch    1/100 Batch 2/3 Cost: 218.392639\n",
            "Epoch    1/100 Batch 3/3 Cost: 41.357563\n",
            "Epoch    2/100 Batch 1/3 Cost: 41.481598\n",
            "Epoch    2/100 Batch 2/3 Cost: 8.328976\n",
            "Epoch    2/100 Batch 3/3 Cost: 1.319820\n",
            "Epoch    3/100 Batch 1/3 Cost: 4.173813\n",
            "Epoch    3/100 Batch 2/3 Cost: 0.094961\n",
            "Epoch    3/100 Batch 3/3 Cost: 0.000263\n",
            "Epoch    4/100 Batch 1/3 Cost: 0.067664\n",
            "Epoch    4/100 Batch 2/3 Cost: 2.130779\n",
            "Epoch    4/100 Batch 3/3 Cost: 0.181459\n",
            "Epoch    5/100 Batch 1/3 Cost: 1.864661\n",
            "Epoch    5/100 Batch 2/3 Cost: 0.133571\n",
            "Epoch    5/100 Batch 3/3 Cost: 0.005211\n",
            "Epoch    6/100 Batch 1/3 Cost: 1.683592\n",
            "Epoch    6/100 Batch 2/3 Cost: 0.476674\n",
            "Epoch    6/100 Batch 3/3 Cost: 0.005561\n",
            "Epoch    7/100 Batch 1/3 Cost: 1.720399\n",
            "Epoch    7/100 Batch 2/3 Cost: 0.609096\n",
            "Epoch    7/100 Batch 3/3 Cost: 0.000914\n",
            "Epoch    8/100 Batch 1/3 Cost: 0.021777\n",
            "Epoch    8/100 Batch 2/3 Cost: 0.109855\n",
            "Epoch    8/100 Batch 3/3 Cost: 4.024390\n",
            "Epoch    9/100 Batch 1/3 Cost: 1.059153\n",
            "Epoch    9/100 Batch 2/3 Cost: 1.118307\n",
            "Epoch    9/100 Batch 3/3 Cost: 0.247792\n",
            "Epoch   10/100 Batch 1/3 Cost: 0.033828\n",
            "Epoch   10/100 Batch 2/3 Cost: 1.897331\n",
            "Epoch   10/100 Batch 3/3 Cost: 0.044058\n",
            "Epoch   11/100 Batch 1/3 Cost: 0.219861\n",
            "Epoch   11/100 Batch 2/3 Cost: 0.008390\n",
            "Epoch   11/100 Batch 3/3 Cost: 3.789289\n",
            "Epoch   12/100 Batch 1/3 Cost: 0.398788\n",
            "Epoch   12/100 Batch 2/3 Cost: 0.676527\n",
            "Epoch   12/100 Batch 3/3 Cost: 3.429923\n",
            "Epoch   13/100 Batch 1/3 Cost: 1.118169\n",
            "Epoch   13/100 Batch 2/3 Cost: 0.160438\n",
            "Epoch   13/100 Batch 3/3 Cost: 3.139184\n",
            "Epoch   14/100 Batch 1/3 Cost: 1.677437\n",
            "Epoch   14/100 Batch 2/3 Cost: 0.391287\n",
            "Epoch   14/100 Batch 3/3 Cost: 0.391350\n",
            "Epoch   15/100 Batch 1/3 Cost: 0.207703\n",
            "Epoch   15/100 Batch 2/3 Cost: 1.852399\n",
            "Epoch   15/100 Batch 3/3 Cost: 0.273476\n",
            "Epoch   16/100 Batch 1/3 Cost: 0.004565\n",
            "Epoch   16/100 Batch 2/3 Cost: 1.696118\n",
            "Epoch   16/100 Batch 3/3 Cost: 0.809742\n",
            "Epoch   17/100 Batch 1/3 Cost: 0.012670\n",
            "Epoch   17/100 Batch 2/3 Cost: 1.895743\n",
            "Epoch   17/100 Batch 3/3 Cost: 0.712017\n",
            "Epoch   18/100 Batch 1/3 Cost: 1.960388\n",
            "Epoch   18/100 Batch 2/3 Cost: 0.445601\n",
            "Epoch   18/100 Batch 3/3 Cost: 0.005786\n",
            "Epoch   19/100 Batch 1/3 Cost: 0.015566\n",
            "Epoch   19/100 Batch 2/3 Cost: 1.832885\n",
            "Epoch   19/100 Batch 3/3 Cost: 0.795470\n",
            "Epoch   20/100 Batch 1/3 Cost: 0.073328\n",
            "Epoch   20/100 Batch 2/3 Cost: 2.073337\n",
            "Epoch   20/100 Batch 3/3 Cost: 0.036351\n",
            "Epoch   21/100 Batch 1/3 Cost: 0.213641\n",
            "Epoch   21/100 Batch 2/3 Cost: 0.011423\n",
            "Epoch   21/100 Batch 3/3 Cost: 3.704227\n",
            "Epoch   22/100 Batch 1/3 Cost: 1.026993\n",
            "Epoch   22/100 Batch 2/3 Cost: 1.461189\n",
            "Epoch   22/100 Batch 3/3 Cost: 0.030754\n",
            "Epoch   23/100 Batch 1/3 Cost: 0.056962\n",
            "Epoch   23/100 Batch 2/3 Cost: 1.832914\n",
            "Epoch   23/100 Batch 3/3 Cost: 0.055426\n",
            "Epoch   24/100 Batch 1/3 Cost: 0.063298\n",
            "Epoch   24/100 Batch 2/3 Cost: 1.822685\n",
            "Epoch   24/100 Batch 3/3 Cost: 0.053800\n",
            "Epoch   25/100 Batch 1/3 Cost: 0.257829\n",
            "Epoch   25/100 Batch 2/3 Cost: 1.807208\n",
            "Epoch   25/100 Batch 3/3 Cost: 0.070549\n",
            "Epoch   26/100 Batch 1/3 Cost: 0.350133\n",
            "Epoch   26/100 Batch 2/3 Cost: 1.863981\n",
            "Epoch   26/100 Batch 3/3 Cost: 0.082555\n",
            "Epoch   27/100 Batch 1/3 Cost: 0.308391\n",
            "Epoch   27/100 Batch 2/3 Cost: 0.016080\n",
            "Epoch   27/100 Batch 3/3 Cost: 3.586994\n",
            "Epoch   28/100 Batch 1/3 Cost: 1.283935\n",
            "Epoch   28/100 Batch 2/3 Cost: 1.491048\n",
            "Epoch   28/100 Batch 3/3 Cost: 0.155751\n",
            "Epoch   29/100 Batch 1/3 Cost: 0.173881\n",
            "Epoch   29/100 Batch 2/3 Cost: 1.718301\n",
            "Epoch   29/100 Batch 3/3 Cost: 0.092055\n",
            "Epoch   30/100 Batch 1/3 Cost: 0.314162\n",
            "Epoch   30/100 Batch 2/3 Cost: 1.875253\n",
            "Epoch   30/100 Batch 3/3 Cost: 0.082274\n",
            "Epoch   31/100 Batch 1/3 Cost: 1.524641\n",
            "Epoch   31/100 Batch 2/3 Cost: 0.564822\n",
            "Epoch   31/100 Batch 3/3 Cost: 0.006400\n",
            "Epoch   32/100 Batch 1/3 Cost: 1.648588\n",
            "Epoch   32/100 Batch 2/3 Cost: 0.515582\n",
            "Epoch   32/100 Batch 3/3 Cost: 0.077411\n",
            "Epoch   33/100 Batch 1/3 Cost: 0.116240\n",
            "Epoch   33/100 Batch 2/3 Cost: 0.033409\n",
            "Epoch   33/100 Batch 3/3 Cost: 3.818215\n",
            "Epoch   34/100 Batch 1/3 Cost: 0.598430\n",
            "Epoch   34/100 Batch 2/3 Cost: 1.622687\n",
            "Epoch   34/100 Batch 3/3 Cost: 0.114242\n",
            "Epoch   35/100 Batch 1/3 Cost: 1.408343\n",
            "Epoch   35/100 Batch 2/3 Cost: 0.665779\n",
            "Epoch   35/100 Batch 3/3 Cost: 0.010154\n",
            "Epoch   36/100 Batch 1/3 Cost: 0.003528\n",
            "Epoch   36/100 Batch 2/3 Cost: 1.799825\n",
            "Epoch   36/100 Batch 3/3 Cost: 0.204397\n",
            "Epoch   37/100 Batch 1/3 Cost: 0.155645\n",
            "Epoch   37/100 Batch 2/3 Cost: 0.004546\n",
            "Epoch   37/100 Batch 3/3 Cost: 3.784122\n",
            "Epoch   38/100 Batch 1/3 Cost: 1.026476\n",
            "Epoch   38/100 Batch 2/3 Cost: 0.670995\n",
            "Epoch   38/100 Batch 3/3 Cost: 0.946684\n",
            "Epoch   39/100 Batch 1/3 Cost: 0.090997\n",
            "Epoch   39/100 Batch 2/3 Cost: 1.991036\n",
            "Epoch   39/100 Batch 3/3 Cost: 0.195149\n",
            "Epoch   40/100 Batch 1/3 Cost: 0.153628\n",
            "Epoch   40/100 Batch 2/3 Cost: 1.884213\n",
            "Epoch   40/100 Batch 3/3 Cost: 0.051608\n",
            "Epoch   41/100 Batch 1/3 Cost: 1.680143\n",
            "Epoch   41/100 Batch 2/3 Cost: 0.092407\n",
            "Epoch   41/100 Batch 3/3 Cost: 0.154765\n",
            "Epoch   42/100 Batch 1/3 Cost: 1.674819\n",
            "Epoch   42/100 Batch 2/3 Cost: 0.218523\n",
            "Epoch   42/100 Batch 3/3 Cost: 0.515374\n",
            "Epoch   43/100 Batch 1/3 Cost: 0.068048\n",
            "Epoch   43/100 Batch 2/3 Cost: 2.059839\n",
            "Epoch   43/100 Batch 3/3 Cost: 0.031459\n",
            "Epoch   44/100 Batch 1/3 Cost: 1.493804\n",
            "Epoch   44/100 Batch 2/3 Cost: 0.588345\n",
            "Epoch   44/100 Batch 3/3 Cost: 0.092955\n",
            "Epoch   45/100 Batch 1/3 Cost: 1.737024\n",
            "Epoch   45/100 Batch 2/3 Cost: 0.203719\n",
            "Epoch   45/100 Batch 3/3 Cost: 0.443231\n",
            "Epoch   46/100 Batch 1/3 Cost: 0.026819\n",
            "Epoch   46/100 Batch 2/3 Cost: 1.992839\n",
            "Epoch   46/100 Batch 3/3 Cost: 0.020220\n",
            "Epoch   47/100 Batch 1/3 Cost: 1.531809\n",
            "Epoch   47/100 Batch 2/3 Cost: 0.696442\n",
            "Epoch   47/100 Batch 3/3 Cost: 0.001283\n",
            "Epoch   48/100 Batch 1/3 Cost: 0.156714\n",
            "Epoch   48/100 Batch 2/3 Cost: 1.979752\n",
            "Epoch   48/100 Batch 3/3 Cost: 0.057412\n",
            "Epoch   49/100 Batch 1/3 Cost: 0.228598\n",
            "Epoch   49/100 Batch 2/3 Cost: 1.796137\n",
            "Epoch   49/100 Batch 3/3 Cost: 0.261825\n",
            "Epoch   50/100 Batch 1/3 Cost: 0.034457\n",
            "Epoch   50/100 Batch 2/3 Cost: 1.821921\n",
            "Epoch   50/100 Batch 3/3 Cost: 0.040360\n",
            "Epoch   51/100 Batch 1/3 Cost: 1.452657\n",
            "Epoch   51/100 Batch 2/3 Cost: 0.292109\n",
            "Epoch   51/100 Batch 3/3 Cost: 0.603789\n",
            "Epoch   52/100 Batch 1/3 Cost: 0.071223\n",
            "Epoch   52/100 Batch 2/3 Cost: 2.031379\n",
            "Epoch   52/100 Batch 3/3 Cost: 0.031395\n",
            "Epoch   53/100 Batch 1/3 Cost: 0.233090\n",
            "Epoch   53/100 Batch 2/3 Cost: 1.781327\n",
            "Epoch   53/100 Batch 3/3 Cost: 0.081567\n",
            "Epoch   54/100 Batch 1/3 Cost: 0.248775\n",
            "Epoch   54/100 Batch 2/3 Cost: 1.780242\n",
            "Epoch   54/100 Batch 3/3 Cost: 0.060247\n",
            "Epoch   55/100 Batch 1/3 Cost: 1.391122\n",
            "Epoch   55/100 Batch 2/3 Cost: 0.369973\n",
            "Epoch   55/100 Batch 3/3 Cost: 0.570701\n",
            "Epoch   56/100 Batch 1/3 Cost: 0.026449\n",
            "Epoch   56/100 Batch 2/3 Cost: 0.080863\n",
            "Epoch   56/100 Batch 3/3 Cost: 4.110927\n",
            "Epoch   57/100 Batch 1/3 Cost: 1.049619\n",
            "Epoch   57/100 Batch 2/3 Cost: 1.025886\n",
            "Epoch   57/100 Batch 3/3 Cost: 0.206624\n",
            "Epoch   58/100 Batch 1/3 Cost: 0.163565\n",
            "Epoch   58/100 Batch 2/3 Cost: 1.852858\n",
            "Epoch   58/100 Batch 3/3 Cost: 0.048360\n",
            "Epoch   59/100 Batch 1/3 Cost: 1.411883\n",
            "Epoch   59/100 Batch 2/3 Cost: 0.352289\n",
            "Epoch   59/100 Batch 3/3 Cost: 0.560008\n",
            "Epoch   60/100 Batch 1/3 Cost: 0.069213\n",
            "Epoch   60/100 Batch 2/3 Cost: 2.031490\n",
            "Epoch   60/100 Batch 3/3 Cost: 0.028920\n",
            "Epoch   61/100 Batch 1/3 Cost: 0.015717\n",
            "Epoch   61/100 Batch 2/3 Cost: 0.221723\n",
            "Epoch   61/100 Batch 3/3 Cost: 3.789883\n",
            "Epoch   62/100 Batch 1/3 Cost: 1.163351\n",
            "Epoch   62/100 Batch 2/3 Cost: 0.992299\n",
            "Epoch   62/100 Batch 3/3 Cost: 0.064430\n",
            "Epoch   63/100 Batch 1/3 Cost: 0.057383\n",
            "Epoch   63/100 Batch 2/3 Cost: 0.157895\n",
            "Epoch   63/100 Batch 3/3 Cost: 3.702876\n",
            "Epoch   64/100 Batch 1/3 Cost: 1.009774\n",
            "Epoch   64/100 Batch 2/3 Cost: 0.639456\n",
            "Epoch   64/100 Batch 3/3 Cost: 0.952989\n",
            "Epoch   65/100 Batch 1/3 Cost: 0.007691\n",
            "Epoch   65/100 Batch 2/3 Cost: 1.762010\n",
            "Epoch   65/100 Batch 3/3 Cost: 0.710267\n",
            "Epoch   66/100 Batch 1/3 Cost: 1.905132\n",
            "Epoch   66/100 Batch 2/3 Cost: 0.135315\n",
            "Epoch   66/100 Batch 3/3 Cost: 0.389577\n",
            "Epoch   67/100 Batch 1/3 Cost: 0.049772\n",
            "Epoch   67/100 Batch 2/3 Cost: 2.144753\n",
            "Epoch   67/100 Batch 3/3 Cost: 0.155426\n",
            "Epoch   68/100 Batch 1/3 Cost: 0.148262\n",
            "Epoch   68/100 Batch 2/3 Cost: 1.861409\n",
            "Epoch   68/100 Batch 3/3 Cost: 0.215952\n",
            "Epoch   69/100 Batch 1/3 Cost: 0.196657\n",
            "Epoch   69/100 Batch 2/3 Cost: 0.019075\n",
            "Epoch   69/100 Batch 3/3 Cost: 3.610731\n",
            "Epoch   70/100 Batch 1/3 Cost: 0.375570\n",
            "Epoch   70/100 Batch 2/3 Cost: 1.252909\n",
            "Epoch   70/100 Batch 3/3 Cost: 1.308380\n",
            "Epoch   71/100 Batch 1/3 Cost: 0.000937\n",
            "Epoch   71/100 Batch 2/3 Cost: 0.135938\n",
            "Epoch   71/100 Batch 3/3 Cost: 3.916940\n",
            "Epoch   72/100 Batch 1/3 Cost: 1.025045\n",
            "Epoch   72/100 Batch 2/3 Cost: 0.590337\n",
            "Epoch   72/100 Batch 3/3 Cost: 0.919271\n",
            "Epoch   73/100 Batch 1/3 Cost: 1.819604\n",
            "Epoch   73/100 Batch 2/3 Cost: 0.402639\n",
            "Epoch   73/100 Batch 3/3 Cost: 0.030835\n",
            "Epoch   74/100 Batch 1/3 Cost: 0.005541\n",
            "Epoch   74/100 Batch 2/3 Cost: 1.801036\n",
            "Epoch   74/100 Batch 3/3 Cost: 0.755326\n",
            "Epoch   75/100 Batch 1/3 Cost: 1.882036\n",
            "Epoch   75/100 Batch 2/3 Cost: 0.461035\n",
            "Epoch   75/100 Batch 3/3 Cost: 0.000913\n",
            "Epoch   76/100 Batch 1/3 Cost: 0.117420\n",
            "Epoch   76/100 Batch 2/3 Cost: 1.912453\n",
            "Epoch   76/100 Batch 3/3 Cost: 0.207986\n",
            "Epoch   77/100 Batch 1/3 Cost: 1.731002\n",
            "Epoch   77/100 Batch 2/3 Cost: 0.130181\n",
            "Epoch   77/100 Batch 3/3 Cost: 0.005798\n",
            "Epoch   78/100 Batch 1/3 Cost: 1.723034\n",
            "Epoch   78/100 Batch 2/3 Cost: 0.120441\n",
            "Epoch   78/100 Batch 3/3 Cost: 0.013438\n",
            "Epoch   79/100 Batch 1/3 Cost: 1.550028\n",
            "Epoch   79/100 Batch 2/3 Cost: 0.640340\n",
            "Epoch   79/100 Batch 3/3 Cost: 0.000108\n",
            "Epoch   80/100 Batch 1/3 Cost: 0.015312\n",
            "Epoch   80/100 Batch 2/3 Cost: 1.817091\n",
            "Epoch   80/100 Batch 3/3 Cost: 0.028173\n",
            "Epoch   81/100 Batch 1/3 Cost: 0.286571\n",
            "Epoch   81/100 Batch 2/3 Cost: 1.818556\n",
            "Epoch   81/100 Batch 3/3 Cost: 0.085706\n",
            "Epoch   82/100 Batch 1/3 Cost: 1.425378\n",
            "Epoch   82/100 Batch 2/3 Cost: 0.590456\n",
            "Epoch   82/100 Batch 3/3 Cost: 0.086117\n",
            "Epoch   83/100 Batch 1/3 Cost: 1.672833\n",
            "Epoch   83/100 Batch 2/3 Cost: 0.202904\n",
            "Epoch   83/100 Batch 3/3 Cost: 0.455032\n",
            "Epoch   84/100 Batch 1/3 Cost: 0.015253\n",
            "Epoch   84/100 Batch 2/3 Cost: 1.929021\n",
            "Epoch   84/100 Batch 3/3 Cost: 0.668514\n",
            "Epoch   85/100 Batch 1/3 Cost: 0.021145\n",
            "Epoch   85/100 Batch 2/3 Cost: 1.877613\n",
            "Epoch   85/100 Batch 3/3 Cost: 0.122718\n",
            "Epoch   86/100 Batch 1/3 Cost: 0.000033\n",
            "Epoch   86/100 Batch 2/3 Cost: 1.768144\n",
            "Epoch   86/100 Batch 3/3 Cost: 0.165002\n",
            "Epoch   87/100 Batch 1/3 Cost: 1.602307\n",
            "Epoch   87/100 Batch 2/3 Cost: 0.097323\n",
            "Epoch   87/100 Batch 3/3 Cost: 0.572016\n",
            "Epoch   88/100 Batch 1/3 Cost: 1.940302\n",
            "Epoch   88/100 Batch 2/3 Cost: 0.340681\n",
            "Epoch   88/100 Batch 3/3 Cost: 0.020376\n",
            "Epoch   89/100 Batch 1/3 Cost: 0.007218\n",
            "Epoch   89/100 Batch 2/3 Cost: 0.112103\n",
            "Epoch   89/100 Batch 3/3 Cost: 3.923768\n",
            "Epoch   90/100 Batch 1/3 Cost: 1.537506\n",
            "Epoch   90/100 Batch 2/3 Cost: 0.424429\n",
            "Epoch   90/100 Batch 3/3 Cost: 0.034706\n",
            "Epoch   91/100 Batch 1/3 Cost: 0.267572\n",
            "Epoch   91/100 Batch 2/3 Cost: 0.006821\n",
            "Epoch   91/100 Batch 3/3 Cost: 3.492831\n",
            "Epoch   92/100 Batch 1/3 Cost: 1.559389\n",
            "Epoch   92/100 Batch 2/3 Cost: 0.290525\n",
            "Epoch   92/100 Batch 3/3 Cost: 0.291791\n",
            "Epoch   93/100 Batch 1/3 Cost: 1.475795\n",
            "Epoch   93/100 Batch 2/3 Cost: 0.284492\n",
            "Epoch   93/100 Batch 3/3 Cost: 0.522673\n",
            "Epoch   94/100 Batch 1/3 Cost: 0.059327\n",
            "Epoch   94/100 Batch 2/3 Cost: 0.035598\n",
            "Epoch   94/100 Batch 3/3 Cost: 3.782104\n",
            "Epoch   95/100 Batch 1/3 Cost: 0.439779\n",
            "Epoch   95/100 Batch 2/3 Cost: 1.546417\n",
            "Epoch   95/100 Batch 3/3 Cost: 0.172562\n",
            "Epoch   96/100 Batch 1/3 Cost: 0.035648\n",
            "Epoch   96/100 Batch 2/3 Cost: 1.651587\n",
            "Epoch   96/100 Batch 3/3 Cost: 0.219812\n",
            "Epoch   97/100 Batch 1/3 Cost: 1.543663\n",
            "Epoch   97/100 Batch 2/3 Cost: 0.498239\n",
            "Epoch   97/100 Batch 3/3 Cost: 0.000454\n",
            "Epoch   98/100 Batch 1/3 Cost: 1.733304\n",
            "Epoch   98/100 Batch 2/3 Cost: 0.114609\n",
            "Epoch   98/100 Batch 3/3 Cost: 0.003496\n",
            "Epoch   99/100 Batch 1/3 Cost: 1.529057\n",
            "Epoch   99/100 Batch 2/3 Cost: 0.629827\n",
            "Epoch   99/100 Batch 3/3 Cost: 0.000000\n",
            "Epoch  100/100 Batch 1/3 Cost: 0.156591\n",
            "Epoch  100/100 Batch 2/3 Cost: 1.909773\n",
            "Epoch  100/100 Batch 3/3 Cost: 0.039926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**커스텀 데이터셋**"
      ],
      "metadata": {
        "id": "s2RpAKYFZb7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "3bUWn-3TYVOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 상속\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  # 총 데이터의 개수를 리턴\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "m75ppJBfZs8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "model = torch.nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6hWGmY6Zu0u",
        "outputId": "68918a98-4330-4413-e229-12cca55a0453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 45851.796875\n",
            "Epoch    0/20 Batch 2/3 Cost: 19506.183594\n",
            "Epoch    0/20 Batch 3/3 Cost: 7026.316895\n",
            "Epoch    1/20 Batch 1/3 Cost: 1684.020996\n",
            "Epoch    1/20 Batch 2/3 Cost: 266.646179\n",
            "Epoch    1/20 Batch 3/3 Cost: 26.550106\n",
            "Epoch    2/20 Batch 1/3 Cost: 83.593903\n",
            "Epoch    2/20 Batch 2/3 Cost: 24.049982\n",
            "Epoch    2/20 Batch 3/3 Cost: 2.103199\n",
            "Epoch    3/20 Batch 1/3 Cost: 12.119308\n",
            "Epoch    3/20 Batch 2/3 Cost: 10.123870\n",
            "Epoch    3/20 Batch 3/3 Cost: 12.433867\n",
            "Epoch    4/20 Batch 1/3 Cost: 2.666785\n",
            "Epoch    4/20 Batch 2/3 Cost: 14.500903\n",
            "Epoch    4/20 Batch 3/3 Cost: 15.499821\n",
            "Epoch    5/20 Batch 1/3 Cost: 11.694451\n",
            "Epoch    5/20 Batch 2/3 Cost: 5.548173\n",
            "Epoch    5/20 Batch 3/3 Cost: 18.932775\n",
            "Epoch    6/20 Batch 1/3 Cost: 5.202803\n",
            "Epoch    6/20 Batch 2/3 Cost: 9.282139\n",
            "Epoch    6/20 Batch 3/3 Cost: 17.616014\n",
            "Epoch    7/20 Batch 1/3 Cost: 3.832563\n",
            "Epoch    7/20 Batch 2/3 Cost: 13.327251\n",
            "Epoch    7/20 Batch 3/3 Cost: 14.064789\n",
            "Epoch    8/20 Batch 1/3 Cost: 5.236905\n",
            "Epoch    8/20 Batch 2/3 Cost: 13.235756\n",
            "Epoch    8/20 Batch 3/3 Cost: 19.654860\n",
            "Epoch    9/20 Batch 1/3 Cost: 11.507279\n",
            "Epoch    9/20 Batch 2/3 Cost: 5.370855\n",
            "Epoch    9/20 Batch 3/3 Cost: 18.895615\n",
            "Epoch   10/20 Batch 1/3 Cost: 6.610810\n",
            "Epoch   10/20 Batch 2/3 Cost: 20.965734\n",
            "Epoch   10/20 Batch 3/3 Cost: 4.041182\n",
            "Epoch   11/20 Batch 1/3 Cost: 14.383995\n",
            "Epoch   11/20 Batch 2/3 Cost: 6.888880\n",
            "Epoch   11/20 Batch 3/3 Cost: 4.183952\n",
            "Epoch   12/20 Batch 1/3 Cost: 10.668526\n",
            "Epoch   12/20 Batch 2/3 Cost: 10.714263\n",
            "Epoch   12/20 Batch 3/3 Cost: 3.585376\n",
            "Epoch   13/20 Batch 1/3 Cost: 11.319806\n",
            "Epoch   13/20 Batch 2/3 Cost: 5.684413\n",
            "Epoch   13/20 Batch 3/3 Cost: 18.512867\n",
            "Epoch   14/20 Batch 1/3 Cost: 6.235440\n",
            "Epoch   14/20 Batch 2/3 Cost: 13.972604\n",
            "Epoch   14/20 Batch 3/3 Cost: 3.730882\n",
            "Epoch   15/20 Batch 1/3 Cost: 6.628374\n",
            "Epoch   15/20 Batch 2/3 Cost: 13.677320\n",
            "Epoch   15/20 Batch 3/3 Cost: 4.215034\n",
            "Epoch   16/20 Batch 1/3 Cost: 11.407207\n",
            "Epoch   16/20 Batch 2/3 Cost: 9.479967\n",
            "Epoch   16/20 Batch 3/3 Cost: 4.137577\n",
            "Epoch   17/20 Batch 1/3 Cost: 8.240779\n",
            "Epoch   17/20 Batch 2/3 Cost: 13.667900\n",
            "Epoch   17/20 Batch 3/3 Cost: 1.611710\n",
            "Epoch   18/20 Batch 1/3 Cost: 11.203781\n",
            "Epoch   18/20 Batch 2/3 Cost: 10.035625\n",
            "Epoch   18/20 Batch 3/3 Cost: 1.928028\n",
            "Epoch   19/20 Batch 1/3 Cost: 16.956577\n",
            "Epoch   19/20 Batch 2/3 Cost: 7.557736\n",
            "Epoch   19/20 Batch 3/3 Cost: 10.077641\n",
            "Epoch   20/20 Batch 1/3 Cost: 2.236254\n",
            "Epoch   20/20 Batch 2/3 Cost: 14.630955\n",
            "Epoch   20/20 Batch 3/3 Cost: 15.718292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xt1Ycz_6Z--x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}